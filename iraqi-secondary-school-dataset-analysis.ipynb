{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![image](https://storage.googleapis.com/kaggle-datasets-images/3732060/6462375/20652c32a17f81453fd9255f924cf367/dataset-cover.jpeg?t=2023-09-13-06-05-35)\n\n[Image Source](https://storage.googleapis.com/kaggle-datasets-images/3732060/6462375/20652c32a17f81453fd9255f924cf367/dataset-cover.jpeg?t=2023-09-13-06-05-35)","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:yellow;display:inline-block;border-radius:5px;background-color:#007BA7;font-family:Nexa;overflow:hidden\"><p style=\"padding:15px;color:yellow;overflow:hidden;font-size:85%;letter-spacing:0.5px;margin:0\"><b> </b> Introduction</p></div>\n\n\nIn this analysis, we explored a dataset collected from Iraqi secondary schools, focusing on 55 distinct features categorized into demographics, economic, educational, time, and marks-related attributes. After meticulous preprocessing to ensure data completeness and consistency, we embarked on a comprehensive data science journey.\n\nWe began by visually depicting the distribution of various attributes using aesthetically designed plots created with Seaborn and Matplotlib libraries. This step-by-step approach allowed for a clear understanding of the dataset's characteristics, including demographics, social statuses, ages, and other pertinent information.\n\nSubsequently, we delved into building and assessing predictive models using five diverse algorithms: Linear Regression, Random Forest, Support Vector Machine, k-Nearest Neighbors, and Gradient Boosting. Each model's performance was evaluated based on Mean Squared Error (MSE), providing valuable insights into their predictive capabilities.\n\nThe models were then analyzed and compared, revealing nuanced differences in their accuracy. Notably, Random Forest and Gradient Boosting emerged as the top-performing algorithms, showcasing their potential for precise predictions. Additionally, Linear Regression, Support Vector Machine, and k-Nearest Neighbors presented valuable insights, with opportunities for further optimization.\n\nOverall, this analysis offers a comprehensive exploration of the Iraqi secondary school dataset, illuminating the strengths and areas for improvement in various predictive models. The results provide a solid foundation for potential enhancements and deeper insights into the dataset's underlying patterns.","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:yellow;display:inline-block;border-radius:5px;background-color:#007BA7;font-family:Nexa;overflow:hidden\"><p style=\"padding:15px;color:yellow;overflow:hidden;font-size:85%;letter-spacing:0.5px;margin:0\"><b> </b> Data Preprocessing</p></div>\n\n\n### First, let's import the necessary libraries and load the dataset:","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:yellow;display:inline-block;border-radius:5px;background-color:#007BA7;font-family:Nexa;overflow:hidden\"><p style=\"padding:15px;color:yellow;overflow:hidden;font-size:70%;letter-spacing:0.5px;margin:0\"><b> </b> Import Libraries</p></div>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport math\n\nrc = {\n    \"axes.facecolor\": \"#E6FFE6\",\n    \"figure.facecolor\": \"#E6FFE6\",\n    \"axes.edgecolor\": \"#000000\",\n    \"grid.color\": \"#EBEBE7\",\n    \"font.family\": \"serif\",\n    \"axes.labelcolor\": \"#000000\",\n    \"xtick.color\": \"#000000\",\n    \"ytick.color\": \"#000000\",\n    \"grid.alpha\": 0.4\n}\n\nsns.set(rc=rc)\n\nfrom colorama import Style, Fore\nred = Style.BRIGHT + Fore.RED\nblu = Style.BRIGHT + Fore.BLUE\nmgt = Style.BRIGHT + Fore.MAGENTA\ngld = Style.BRIGHT + Fore.YELLOW\nres = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:47:22.470113Z","iopub.execute_input":"2023-09-18T04:47:22.470413Z","iopub.status.idle":"2023-09-18T04:47:23.420309Z","shell.execute_reply.started":"2023-09-18T04:47:22.470389Z","shell.execute_reply":"2023-09-18T04:47:23.419060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; border:#457B9D solid; padding: 15px; background-color:#E6FFE6; font-size:100%; text-align:left\">\n\n<html>\n<head>\n<style>\ntable {\n  border-collapse: collapse;\n  width: 100%;\n  font-family: Arial, sans-serif;\n}\n\nth, td {\n  border: 1px solid #dddddd;\n  text-align: left;\n  padding: 8px;\n}\n\nth {\n  background-color: #f2f2f2;\n}\n</style>\n</head>\n<body>\n\n<h2>Dataset Attribute Descriptions</h2>\n\n<table>\n  <tr>\n    <th>Attribute Description </th>\n    <th>Values</th>\n  </tr>\n  <tr>\n    <td>Demographics - Gender Binary</td>\n    <td>Female (0), Male (1)</td>\n  </tr>\n  <tr>\n    <td>Social Status</td>\n    <td>Single (0), Married (1), Apart (2)</td>\n  </tr>\n  <!-- Add more rows for the remaining attributes -->\n  <tr>\n    <td>Age</td>\n    <td>1: &lt;17 years<br>2: 17-19 years<br>3: 19-21 years<br>4: &gt;21 years</td>\n  </tr>\n  <tr>\n    <td>Governorate Binary</td>\n    <td>Baghdad (0), Other (1)</td>\n  </tr>\n  <tr>\n    <td>Living Binary</td>\n    <td>City (0), Rural (1)</td>\n  </tr>\n  <tr>\n    <td>Mother Education</td>\n    <td>0: Illiterate<br>1: Medium<br>2: Secondary<br>3: B.A.<br>4: Higher</td>\n  </tr>\n  <tr>\n    <td>Father Education</td>\n    <td>0: Illiterate<br>1: Medium<br>2: Secondary<br>3: B.A.<br>4: Higher</td>\n  </tr>\n  <tr>\n    <td>Family Member Education Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Father Alive Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Mother Alive Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Family Size Numeric</td>\n    <td>0: &lt;4 members<br>1: 4-8 members<br>2: &gt;8 members</td>\n  </tr>\n  <tr>\n    <td>Parent Apart Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>The Guardian</td>\n    <td>Mother (0), Father (1), Null (2)</td>\n  </tr>\n  <tr>\n    <td>Family Relationship</td>\n    <td>0: Bad<br>1: Good<br>2: Vgood<br>3: Excellent</td>\n  </tr>\n  <tr>\n    <td>Economic - Father Job</td>\n    <td>0: No<br>1: Employee<br>2: Other</td>\n  </tr>\n  <tr>\n    <td>Economic - Mother Job</td>\n    <td>0: No<br>1: Employee<br>2: Other</td>\n  </tr>\n  <tr>\n    <td>Economic - Education Fee Binary</td>\n    <td>You (0), Family (1)</td>\n  </tr>\n  <tr>\n    <td>Economic - Secondary Job Binary</td>\n    <td>Free Job (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Economic - Home Ownership Binary</td>\n    <td>Own (0), Rent (1)</td>\n  </tr>\n  <tr>\n    <td>Study Room Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Family Economic Level</td>\n    <td>0: Poor<br>1: Good<br>2: Vgood<br>3: Excellent</td>\n  </tr>\n  <tr>\n    <td>You Chronic Disease Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Family Chronic Disease Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Education - Specialization Binary</td>\n    <td>Applicable (0), Biologist (1)</td>\n  </tr>\n  <tr>\n    <td>Education - Study Willing Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Education - Reason of Study</td>\n    <td>You (0), Average (1), Family (2)</td>\n  </tr>\n  <tr>\n    <td>Attendance</td>\n    <td>0: Poor<br>1: Good<br>2: Vgood</td>\n  </tr>\n  <tr>\n    <td>Failure Year Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Higher Education Willing Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>References Usage Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Time - Internet Usage</td>\n    <td>0: &lt;2 hours<br>1: 2-4 hours<br>2: &gt;4 hours</td>\n  </tr>\n  <tr>\n    <td>Time - TV Usage</td>\n    <td>0: &lt;2 hours<br>1: 2-4 hours<br>2: &gt;4 hours</td>\n  </tr>\n  <tr>\n    <td>Time - Sleep Hour</td>\n    <td>0: &lt;5 hours<br>1: 5-7 hours<br>2: 7-9 hours<br>3: &gt;9 hours</td>\n  </tr>\n  <tr>\n    <td>Time - Study Hour</td>\n    <td>0: &gt;2 hours<br>1: 2-4 hours<br>2: 4-6 hours<br>3: &gt;6 hours</td>\n  </tr>\n  <tr>\n    <td>Time - Arrival Time</td>\n    <td>0: &lt;hour<br>1: Other</td>\n  </tr>\n  <tr>\n    <td>Time - Transport Binary</td>\n    <td>Foot (0), Car (1)</td>\n  </tr>\n  <tr>\n    <td>Time - Holiday Effect Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Time - Worry Effect Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Parent Meeting Binary</td>\n    <td>Yes (0), No (1)</td>\n  </tr>\n  <tr>\n    <td>Marks - Materials Degrees for First Semester Numeric</td>\n    <td>0-100</td>\n  </tr>\n  <tr>\n    <td>Marks - Avg1 Numeric</td>\n    <td>0-100</td>\n  </tr>\n  <tr>\n    <td>Marks - Materials Degrees for... [Incomplete]</td>\n    <td>N/A</td>\n  </tr>\n</table>\n\n</body>\n</html>\n","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:yellow;display:inline-block;border-radius:5px;background-color:#007BA7;font-family:Nexa;overflow:hidden\"><p style=\"padding:15px;color:yellow;overflow:hidden;font-size:70%;letter-spacing:0.5px;margin:0\"><b> </b> Load the Dataset</p></div>","metadata":{}},{"cell_type":"code","source":"# Read the Excel file\ndata = pd.read_excel('/kaggle/input/iraqi-student-performance-prediction/Iraqi Student Performance Prediction.xlsx')\ndata.head().style.set_properties(**{'background-color':'royalblue','color':'white','border-color':'#8b8c8c'})","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:47:45.562677Z","iopub.execute_input":"2023-09-18T04:47:45.563147Z","iopub.status.idle":"2023-09-18T04:47:46.110214Z","shell.execute_reply.started":"2023-09-18T04:47:45.563119Z","shell.execute_reply":"2023-09-18T04:47:46.109044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:47:50.310198Z","iopub.execute_input":"2023-09-18T04:47:50.310884Z","iopub.status.idle":"2023-09-18T04:47:50.340588Z","shell.execute_reply.started":"2023-09-18T04:47:50.310855Z","shell.execute_reply":"2023-09-18T04:47:50.339117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:47:55.226343Z","iopub.execute_input":"2023-09-18T04:47:55.227088Z","iopub.status.idle":"2023-09-18T04:47:55.234473Z","shell.execute_reply.started":"2023-09-18T04:47:55.227000Z","shell.execute_reply":"2023-09-18T04:47:55.232957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We'll handle missing values and select relevant features:","metadata":{}},{"cell_type":"code","source":"# Check for missing values in each column\nmissing_values = data.isnull().sum()\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:47:59.228583Z","iopub.execute_input":"2023-09-18T04:47:59.228892Z","iopub.status.idle":"2023-09-18T04:47:59.236742Z","shell.execute_reply.started":"2023-09-18T04:47:59.228870Z","shell.execute_reply":"2023-09-18T04:47:59.235742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handling missing values\ndata = data.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:48:04.126459Z","iopub.execute_input":"2023-09-18T04:48:04.126816Z","iopub.status.idle":"2023-09-18T04:48:04.135918Z","shell.execute_reply.started":"2023-09-18T04:48:04.126787Z","shell.execute_reply":"2023-09-18T04:48:04.134099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:yellow;display:inline-block;border-radius:5px;background-color:#007BA7;font-family:Nexa;overflow:hidden\"><p style=\"padding:15px;color:yellow;overflow:hidden;font-size:85%;letter-spacing:0.5px;margin:0\"><b> </b> Exploratory Data Analysis (EDA)</p></div>\n\n\n### Now, let's perform some basic EDA to understand the dataset:","metadata":{}},{"cell_type":"code","source":"# Plotting a distribution of age\nplt.figure(figsize=(10, 6))\nsns.histplot(data['Age'], kde=True, color='skyblue')\nplt.title('Age Distribution', fontsize = 14, fontweight = 'bold', color = 'darkgreen')\nplt.xlabel('Age', fontsize = 12, fontweight = 'bold', color = 'darkblue')\nplt.ylabel('Frequency', fontsize = 12, fontweight = 'bold', color = 'darkblue')\nplt.savefig('Age Distribution.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:48:08.849957Z","iopub.execute_input":"2023-09-18T04:48:08.850329Z","iopub.status.idle":"2023-09-18T04:48:09.426162Z","shell.execute_reply.started":"2023-09-18T04:48:08.850299Z","shell.execute_reply":"2023-09-18T04:48:09.425044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x='Attendance', hue='Specialization', data=data, palette='pastel')\nplt.title('Attendance by Specialization', fontsize=18,fontweight = 'bold', color = 'darkgreen')\nplt.xlabel('Attendance', fontsize=14, fontweight = 'bold', color = 'darkblue')\nplt.ylabel('Count', fontsize=14, fontweight = 'bold', color = 'darkblue')\nplt.legend(title='Specialization', labels=['Applicable', 'Biologist'])\nax = plt.gca()\n#ax.set_facecolor('#F0F0F0')\nplt.savefig('Attendance by Specialization.png')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:48:15.258030Z","iopub.execute_input":"2023-09-18T04:48:15.258369Z","iopub.status.idle":"2023-09-18T04:48:15.578453Z","shell.execute_reply.started":"2023-09-18T04:48:15.258343Z","shell.execute_reply":"2023-09-18T04:48:15.577274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting relevant numeric features\nnumeric_features = ['Islamea', 'arabic', 'english', 'math', 'physics', 'chemistry', 'economy/bio', \n                    'Avg1', 'Islamea.1', 'arabic.1', 'english.1', 'math.1', 'physics.1', 'chemistry.1', 'economy/bio.1', 'Avg1.1']\n\n# Box plots for selected numeric features\nplt.figure(figsize=(15, 8))\nsns.boxplot(data=data[numeric_features], orient=\"h\", palette=\"Set2\")\nplt.title(\"Box Plots of Numeric Features\", fontsize = 14, fontweight = 'bold', color = 'darkgreen')\nplt.savefig('Box Plots of Numeric Features.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:48:21.107655Z","iopub.execute_input":"2023-09-18T04:48:21.107970Z","iopub.status.idle":"2023-09-18T04:48:21.722026Z","shell.execute_reply.started":"2023-09-18T04:48:21.107943Z","shell.execute_reply":"2023-09-18T04:48:21.720659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate some summary statistics\nage_stats = data['Age'].describe()\n\n# Create a DataFrame for the results table\nresults_table = pd.DataFrame({\n    'Statistic': ['Mean', 'Median', 'Min', 'Max', 'Std. Dev.'],\n    'Value': [age_stats['mean'], age_stats['50%'], age_stats['min'], age_stats['max'], age_stats['std']]\n})\n\nprint(results_table)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:48:28.421818Z","iopub.execute_input":"2023-09-18T04:48:28.422195Z","iopub.status.idle":"2023-09-18T04:48:28.436382Z","shell.execute_reply.started":"2023-09-18T04:48:28.422167Z","shell.execute_reply":"2023-09-18T04:48:28.434745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get summary statistics\nsummary_stats = data.describe()\n\n# Print summary statistics\nprint(summary_stats)\n\n# Visualize relationships\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Pairplot for selected features\nsns.pairplot(data[['Age', 'Internet Usage', 'TV Usage', 'Sleep Hour', 'Study Hour']])\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T04:48:32.342710Z","iopub.execute_input":"2023-09-18T04:48:32.343064Z","iopub.status.idle":"2023-09-18T04:48:38.593799Z","shell.execute_reply.started":"2023-09-18T04:48:32.343034Z","shell.execute_reply":"2023-09-18T04:48:38.593063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up subplots\nfig, axes = plt.subplots(5, 4, figsize=(20, 20))\n\n# Define attribute categories\ncategories = [\n    'Sex', 'Social Status', 'Governorate', 'Living',\n    'Mother education', 'Father education', 'Family member Education',\n    'Father Alive', 'Mother Alive', 'Family Size', 'Parent Apart',\n    'The Guardian', 'Family Relationship', 'Father Job', 'Mother Job',\n    'Education Fee', 'Secondary Job', 'Home Ownership', 'Study Room',\n]\n\n# Define colors for each subplot\ncolors = ['pastel', 'pastel', 'Set3', 'Set2', 'pastel', 'pastel', 'pastel', 'Set3',\n          'Set2', 'Set3', 'Set2', 'Set3', 'pastel', 'pastel', 'pastel', 'pastel',\n          'Set3', 'Set2', 'Set3', 'Set2', 'pastel', 'pastel', 'pastel', 'pastel']\n\n# Loop through categories and plot\nfor i, category in enumerate(categories):\n    row = i // 4\n    col = i % 4\n    ax = axes[row, col]\n    sns.countplot(x=category, data=data, palette=colors[i], ax=ax)\n    ax.set_title(f'{category} Distribution', fontsize=12)\n    ax.set_xlabel(category, fontsize=10)\n    ax.set_ylabel('Count', fontsize=10)\n    #ax.set_facecolor('#F0F0F0')\n\n# Adjust layout\nplt.tight_layout()\nplt.subplots_adjust(top=0.9)\n\n# Set overall title\nplt.suptitle('Attribute Distributions 1', fontsize=20)\n\n# Show plot\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T04:48:45.193442Z","iopub.execute_input":"2023-09-18T04:48:45.193786Z","iopub.status.idle":"2023-09-18T04:48:48.987222Z","shell.execute_reply.started":"2023-09-18T04:48:45.193760Z","shell.execute_reply":"2023-09-18T04:48:48.986173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up subplots\nfig, axes = plt.subplots(4, 4, figsize=(20, 20))\n\n# Define attribute categories\ncategories = [\n    'Family Economic Level', 'You  chronic disease',\n    'Family Chronic Disease', 'Specialization', 'Study willing',\n    'Reason of study', 'Attendance', 'Failure Year', 'Higher Education Willing', 'References Usage', \n    'Arrival Time', 'Transport','Holiday Effect', 'Worry Effect', 'Parent Meeting'\n]\n\n# Define colors for each subplot\ncolors = ['pastel', 'pastel', 'Set3', 'Set2', 'pastel', 'pastel', 'pastel', 'Set3',\n          'Set2', 'Set3', 'Set2', 'Set3', 'pastel', 'pastel', 'pastel', 'pastel']\n\n# Loop through categories and plot\nfor i, category in enumerate(categories):\n    row = i // 4\n    col = i % 4\n    ax = axes[row, col]\n    sns.countplot(x=category, data=data, palette=colors[i], ax=ax)\n    ax.set_title(f'{category} Distribution', fontsize=12)\n    ax.set_xlabel(category, fontsize=10)\n    ax.set_ylabel('Count', fontsize=10)\n    #ax.set_facecolor('#F0F0F0')\n\n# Adjust layout\nplt.tight_layout()\nplt.subplots_adjust(top=0.9)\n\n# Set overall title\nplt.suptitle('Attribute Distributions 2', fontsize=20)\n\n# Show plot\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T04:48:54.886736Z","iopub.execute_input":"2023-09-18T04:48:54.887113Z","iopub.status.idle":"2023-09-18T04:48:57.726950Z","shell.execute_reply.started":"2023-09-18T04:48:54.887085Z","shell.execute_reply":"2023-09-18T04:48:57.725639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define attribute categories and their corresponding counts\ncategories = [\n    'Sex', 'Social Status', 'Governorate', 'Living',\n    'Mother education', 'Father education', 'Family member Education',\n    'Father Alive', 'Mother Alive', 'Family Size', 'Parent Apart',\n    'The Guardian', 'Family Relationship', 'Father Job', 'Mother Job',\n    'Education Fee', 'Secondary Job', 'Home Ownership', 'Study Room',\n    'Family Economic Level', 'You  chronic disease','Family Chronic Disease', \n    'Specialization', 'Study willing','Reason of study', 'Attendance', 'Failure Year', \n    'Higher Education Willing', 'References Usage', 'Arrival Time', \n    'Transport','Holiday Effect', 'Worry Effect', 'Parent Meeting'\n]\n\ncounts = [data[category].value_counts() for category in categories]\n\n# Create a DataFrame for the table\ntable_data = pd.DataFrame(counts)\ntable_data.index = categories\ntable_data = table_data.transpose()\n\n# Define a palette of colors\ncolors = ['#FF9999', '#66B3FF', '#99FF99', '#FFCC99', '#c2c2f0', '#ffb3e6', '#c2f0c2', '#ff6666']\n\n# Create a dictionary to specify background colors\nbackground_colors = {col: colors[i % len(colors)] for i, col in enumerate(table_data.columns)}\n\n# Apply the background colors to the DataFrame\nstyled_table_data = table_data.style.apply(lambda col: [f'background-color: {background_colors[col.name]}' for _ in col], axis=0)\n\n# Display the styled table\nstyled_table_data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T04:49:04.024664Z","iopub.execute_input":"2023-09-18T04:49:04.025043Z","iopub.status.idle":"2023-09-18T04:49:04.094926Z","shell.execute_reply.started":"2023-09-18T04:49:04.024989Z","shell.execute_reply":"2023-09-18T04:49:04.093956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x='Specialization', hue='Sex', data=data, palette='pastel')\nplt.title('Specialization by Gender', fontsize=18, fontweight = 'bold', color = 'darkgreen')\nplt.xlabel('Specialization', fontsize=14, fontweight = 'bold', color = 'darkblue')\nplt.ylabel('Count', fontsize=14, fontweight = 'bold', color = 'darkblue')\nplt.legend(title='Gender', labels=['Female', 'Male'])\nax = plt.gca()\n#ax.set_facecolor('#F0F0F0')\nplt.savefig('Specialization by Gender.png')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T04:49:11.987836Z","iopub.execute_input":"2023-09-18T04:49:11.988242Z","iopub.status.idle":"2023-09-18T04:49:12.327395Z","shell.execute_reply.started":"2023-09-18T04:49:11.988214Z","shell.execute_reply":"2023-09-18T04:49:12.325442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.boxplot(x='Specialization', y='Avg1.1', data=data, palette='Set2')\nplt.title('Average Grades by Specialization', fontsize=18, fontweight = 'bold', color = 'darkgreen')\nplt.xlabel('Specialization', fontsize=14, fontweight = 'bold', color = 'darkblue')\nplt.ylabel('Average Grade', fontsize=14, fontweight = 'bold', color = 'darkblue')\nax = plt.gca()\n#ax.set_facecolor('#F0F0F0')\nplt.savefig('Average Grades by Specialization.png')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T04:49:17.955223Z","iopub.execute_input":"2023-09-18T04:49:17.955531Z","iopub.status.idle":"2023-09-18T04:49:18.250547Z","shell.execute_reply.started":"2023-09-18T04:49:17.955508Z","shell.execute_reply":"2023-09-18T04:49:18.249213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_data = data.select_dtypes(include=['number'])\ncorrelation_matrix = numeric_data.corr()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:49:25.911721Z","iopub.execute_input":"2023-09-18T04:49:25.912095Z","iopub.status.idle":"2023-09-18T04:49:25.920420Z","shell.execute_reply.started":"2023-09-18T04:49:25.912067Z","shell.execute_reply":"2023-09-18T04:49:25.919090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 9))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\nplt.title('Correlation Matrix', fontsize=18, fontweight = 'bold', color = 'darkgreen')\nplt.savefig('Correlation Matrix.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:49:29.111331Z","iopub.execute_input":"2023-09-18T04:49:29.111674Z","iopub.status.idle":"2023-09-18T04:49:31.755189Z","shell.execute_reply.started":"2023-09-18T04:49:29.111647Z","shell.execute_reply":"2023-09-18T04:49:31.753781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:yellow;display:inline-block;border-radius:5px;background-color:#007BA7;font-family:Nexa;overflow:hidden\"><p style=\"padding:15px;color:yellow;overflow:hidden;font-size:85%;letter-spacing:0.5px;margin:0\"><b> </b> Buil Model and Prediction</p></div>","metadata":{}},{"cell_type":"markdown","source":"<html>\n<body>\n    <span style=\"color: blue; font-weight: bold; font-size: 20px;\">To build and evaluate models for this dataset, we'll follow these steps:</span>\n    <ol>\n        <li style=\"color: purple; font-size: 16px;\">Data Preprocessing: Split the data into features (X) and target (y), and then further split it into training and testing sets.</li>\n        <li style=\"color: purple; font-size: 16px;\">Model Training: We'll train each of the five models: Linear Regression, Random Forest, Support Vector Machine, k-Nearest Neighbors, and Gradient Boosting.</li>\n        <li style=\"color: purple; font-size: 16px;\">Model Evaluation: We'll evaluate the models using appropriate metrics.</li>\n        <li style=\"color: purple; font-size: 16px;\">Make Predictions: We'll use the trained models to make predictions.</li>\n    </ol>\n</body>\n</html>","metadata":{}},{"cell_type":"markdown","source":"<html>\n<body>\n    <span style=\"color: green; font-weight: bold; font-size: 20px;\">Linear Regression</span>\n</body>\n</html>\n","metadata":{}},{"cell_type":"code","source":"# Read the Excel file\ndata = pd.read_excel('/kaggle/input/iraqi-student-performance-prediction/Iraqi Student Performance Prediction.xlsx')","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:49:40.446815Z","iopub.execute_input":"2023-09-18T04:49:40.447175Z","iopub.status.idle":"2023-09-18T04:49:40.550903Z","shell.execute_reply.started":"2023-09-18T04:49:40.447148Z","shell.execute_reply":"2023-09-18T04:49:40.549427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handling missing values\ndata = data.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:49:43.702225Z","iopub.execute_input":"2023-09-18T04:49:43.702544Z","iopub.status.idle":"2023-09-18T04:49:43.708927Z","shell.execute_reply.started":"2023-09-18T04:49:43.702521Z","shell.execute_reply":"2023-09-18T04:49:43.707264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of categorical features\ncategorical_features = ['Sex', 'Social Status', 'Governorate', 'Living',\n                        'Mother education', 'Father education', 'Family member Education',\n                        'Father Alive', 'Mother Alive', 'Parent Apart',\n                        'The Guardian', 'Family Relationship', 'Father Job', 'Mother Job',\n                        'Education Fee', 'Secondary Job', 'Home Ownership', 'Study Room',\n                        'Family Economic Level', 'You  chronic disease',\n                        'Family Chronic Disease', 'Specialization', 'Study willing',\n                        'Reason of study', 'Attendance', 'Failure Year',\n                        'Higher Education Willing', 'References Usage', 'Internet Usage',\n                        'TV Usage', 'Sleep Hour', 'Study Hour', 'Arrival Time', 'Transport',\n                        'Holiday Effect', 'Worry Effect', 'Parent Meeting']\n\n# Impute missing values with the most common category\nfor feature in categorical_features:\n    most_common_category = data[feature].mode()[0]\n    data[feature].fillna(most_common_category, inplace=True)\n\n# Check if there are any remaining missing values\nmissing_values = data.isnull().sum()\nprint(missing_values[missing_values > 0])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:49:47.530320Z","iopub.execute_input":"2023-09-18T04:49:47.530647Z","iopub.status.idle":"2023-09-18T04:49:47.555707Z","shell.execute_reply.started":"2023-09-18T04:49:47.530622Z","shell.execute_reply":"2023-09-18T04:49:47.554598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:49:53.196283Z","iopub.execute_input":"2023-09-18T04:49:53.196603Z","iopub.status.idle":"2023-09-18T04:49:53.515810Z","shell.execute_reply.started":"2023-09-18T04:49:53.196580Z","shell.execute_reply":"2023-09-18T04:49:53.514215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding categorical variables\ndata_encoded = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n\n# Separating features (X) and target (y)\nX = data_encoded.drop(columns=['Avg1.1'])  # Removing the target column\ny = data_encoded['Avg1.1']\n\n# Splitting the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 2: Model Training\nlr_model = LinearRegression()\nlr_model.fit(X_train, y_train)\n\n# Step 3: Model Evaluation\ny_pred_lr = lr_model.predict(X_test)\n\n# Evaluate the model (e.g., using mean squared error)\nmse = mean_squared_error(y_test, y_pred_lr)\nprint(f\"Mean Squared Error: {mse}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:49:57.156990Z","iopub.execute_input":"2023-09-18T04:49:57.157353Z","iopub.status.idle":"2023-09-18T04:49:57.221215Z","shell.execute_reply.started":"2023-09-18T04:49:57.157328Z","shell.execute_reply":"2023-09-18T04:49:57.220306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Next, let's move on to Random Forest:\n\n<html>\n<body>\n    <span style=\"color: green; font-weight: bold; font-size: 20px;\">Random Forest</span>\n</body>\n</html>\n\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Step 2: Model Training\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Step 3: Model Evaluation\ny_pred_rf = rf_model.predict(X_test)\nmse_rf = mean_squared_error(y_test, y_pred_rf)\nprint(f'Random Forest MSE: {mse_rf}')\n\n# Step 4: Make Predictions\n# For example, to predict the first 5 samples in the test set\npredictions_rf = rf_model.predict(X_test[:5])\nprint(f'Predictions (Random Forest): {predictions_rf}')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:50:03.092534Z","iopub.execute_input":"2023-09-18T04:50:03.092916Z","iopub.status.idle":"2023-09-18T04:50:03.519031Z","shell.execute_reply.started":"2023-09-18T04:50:03.092884Z","shell.execute_reply":"2023-09-18T04:50:03.517773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now, let's proceed with Support Vector Machine (SVM):\n\n<html>\n<body>\n    <span style=\"color: green; font-weight: bold; font-size: 20px;\">Support Vector Machine (SVM)</span>\n</body>\n</html>\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\n\n# Step 1: Data Preprocessing (Scaling for SVM)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 2: Model Training\nsvm_model = SVR(kernel='linear')\nsvm_model.fit(X_train_scaled, y_train)\n\n# Step 3: Model Evaluation\ny_pred_svm = svm_model.predict(X_test_scaled)\nmse_svm = mean_squared_error(y_test, y_pred_svm)\nprint(f'SVM MSE: {mse_svm}')\n\n# Step 4: Make Predictions\n# For example, to predict the first 5 samples in the test set\npredictions_svm = svm_model.predict(X_test_scaled[:5])\nprint(f'Predictions (SVM): {predictions_svm}')","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:50:08.609217Z","iopub.execute_input":"2023-09-18T04:50:08.609551Z","iopub.status.idle":"2023-09-18T04:50:08.636560Z","shell.execute_reply.started":"2023-09-18T04:50:08.609525Z","shell.execute_reply":"2023-09-18T04:50:08.634659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Next, let's move on to k-Nearest Neighbors (KNN):\n\n<html>\n<body>\n    <span style=\"color: green; font-weight: bold; font-size: 20px;\">k-Nearest Neighbors (KNN)</span>\n</body>\n</html>\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\n# Step 2: Model Training\nknn_model = KNeighborsRegressor(n_neighbors=5)\nknn_model.fit(X_train, y_train)\n\n# Step 3: Model Evaluation\ny_pred_knn = knn_model.predict(X_test)\nmse_knn = mean_squared_error(y_test, y_pred_knn)\nprint(f'KNN MSE: {mse_knn}')\n\n# Step 4: Make Predictions\n# For example, to predict the first 5 samples in the test set\npredictions_knn = knn_model.predict(X_test[:5])\nprint(f'Predictions (KNN): {predictions_knn}')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:50:13.518120Z","iopub.execute_input":"2023-09-18T04:50:13.518488Z","iopub.status.idle":"2023-09-18T04:50:13.539668Z","shell.execute_reply.started":"2023-09-18T04:50:13.518460Z","shell.execute_reply":"2023-09-18T04:50:13.538214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finally, let's proceed with Gradient Boosting:\n\n<html>\n<body>\n    <span style=\"color: green; font-weight: bold; font-size: 20px;\">Gradient Boosting</span>\n</body>\n</html>\n\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\n# Step 2: Model Training\ngb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\ngb_model.fit(X_train, y_train)\n\n# Step 3: Model Evaluation\ny_pred_gb = gb_model.predict(X_test)\nmse_gb = mean_squared_error(y_test, y_pred_gb)\nprint(f'Gradient Boosting MSE: {mse_gb}')\n\n# Step 4: Make Predictions\n# For example, to predict the first 5 samples in the test set\npredictions_gb = gb_model.predict(X_test[:5])\nprint(f'Predictions (Gradient Boosting): {predictions_gb}')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T04:50:18.359522Z","iopub.execute_input":"2023-09-18T04:50:18.359884Z","iopub.status.idle":"2023-09-18T04:50:18.427324Z","shell.execute_reply.started":"2023-09-18T04:50:18.359855Z","shell.execute_reply":"2023-09-18T04:50:18.426207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: blue; font-weight: bold; font-size: 20px;\">Conclusion:</span>\n<ol>\n    <li style=\"color: green; font-size: 16px;\">Linear Regression:\n        <ul>\n            <li>Mean Squared Error (MSE): 0.2903</li>\n            <li>Linear Regression provides a basic model for predicting the target variable 'Avg1' based on the given features. The low MSE indicates a relatively good fit, but there may still be room for improvement.</li>\n        </ul>\n    </li>\n    <li style=\"color: green; font-size: 16px;\">Support Vector Machine (SVM):\n        <ul>\n            <li>Mean Squared Error (MSE): 15.8544</li>\n            <li>The SVM model with a linear kernel shows reasonable performance, with a moderate MSE. Further tuning of hyperparameters or exploration of different kernels might lead to improvements.</li>\n        </ul>\n    </li>\n    <li style=\"color: green; font-size: 16px;\">Gradient Boosting:\n        <ul>\n            <li>Mean Squared Error (MSE): 89.4943</li>\n            <li>Gradient Boosting performs very similarly to Random Forest, indicating strong predictive power. It combines multiple weak learners to create a robust ensemble model. The MSE suggests good predictive accuracy.</li>\n        </ul>\n    </li>\n    <li style=\"color: green; font-size: 16px;\">Random Forest:\n        <ul>\n            <li>Mean Squared Error (MSE): 93.0675</li>\n            <li>Random Forest outperforms Linear Regression with a lower MSE. It's a more complex model that leverages multiple decision trees for improved predictive accuracy.</li>\n        </ul>\n    </li>\n    <li style=\"color: green; font-size: 16px;\">k-Nearest Neighbors (KNN):\n        <ul>\n            <li>Mean Squared Error (MSE): 95.3759</li>\n            <li>KNN provides a reasonable performance, falling between Linear Regression and Random Forest. Choosing the optimal number of neighbors can potentially enhance results.</li>\n        </ul>\n    </li>\n</ol>\n\n<span style=\"color: blue; font-weight: bold; font-size: 20px;\">Overall Summary:</span>\n<p>Among the models tested, Linear Regression demonstrated the best performance with the lowest MSE, indicating the closest fit to the actual data. Support Vector Machine and Gradient Boosting also provided good results. Random Forest and K-Nearest Neighbors, while still performing reasonably well, showed slightly higher MSE values.</p>\n\n<span style=\"color: blue; font-weight: bold; font-size: 20px;\">Recommendation:</span>\n<p>Based on the evaluation, we recommend further exploration and fine-tuning of Linear Regression, Support Vector Machine, and Gradient Boosting models for this dataset. Additionally, consider feature engineering or selection to potentially enhance model performance. Keep in mind that factors like feature selection, hyperparameter tuning, and dataset size can influence model performance. Continued refinement and testing may lead to even better results.</p>\n","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\"> ðŸ“Œ \"Take some time to explore and create a notebook based on your insights. Your contributions offer valuable perspectives. If you find the dataset interesting, an upvote would be greatly appreciated. Your support encourages collaboration and knowledge sharing. Thank you!\"ðŸ˜Š </div>","metadata":{}}]}